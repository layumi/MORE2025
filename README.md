---
title: "MORE 2025"
collection: pages
permalink: /MORE2025
author_profile: false
---

 <div align='center' > 
  <h2> ACM Web Conference </h2>
 </div>

 <div align='center' style = "vertical-align:middle"> 
  <h2> <img src="https://thewebconf.org/TheACMWebConference.png" margn-right="20px"><a href="https://icmr2024.org/index.html"> ACM Web 2025 </a><a href="https://www2025.thewebconf.org/">(https://www2025.thewebconf.org/)</a>  </h2>
 </div>

 
 <div align='center' > 
  <h2> Workshop on </h2>
  <h2>  Multimedia Object Re-ID: Advancements, Challenges, and Opportunities (MORE 2025) </h2>
  <img src="https://github.com/layumi/MORE2024/assets/8390471/42ee2b73-a4e1-470a-932f-d1fec9ecd025" margn-right="20px" >
 </div>

The accept papers will be published at ACM Web Workshop (top 50%), and go through the same peer review process as the regular papers. Several authors will be invited to do a oral presentation. 

[[Accepted Workshop Proposal]](https://zdzheng.xyz/files/ICMR24_Workshop_Object_Re_ID.pdf)
[[Submission Site]](https://openreview.net/group?id=ACM.org/TheWebConf/2025/Workshop/MORE)


## News
- Paper submission site is online.
- Workshop site is online.


## Abstract
Object re-identification (or object re-ID) has gained significant attention in recent years, fueled by the increasing demand for advanced video analysis and safety systems. In object
re-identification, a query can be of different modalities, such as an image, a video, or natural language, containing or describing the object of interest. 
This workshop aims to bring together researchers, practitioners, and enthusiasts interested in object re-identification to delve into the latest advancements, challenges, and opportunities in this dynamic field. The workshop covers a spectrum of topics related to object re-identification, including but not limited to deep metric learning, multi-view data generation, video-based object re-identification, cross-domain object re-identification and real-world applications.
The workshop provides a platform for researchers to showcase their work, exchange ideas, and foster potential collaborations. Additionally, it serves as a valuable opportunity for practitioners to stay abreast of the latest developments in object re-identification technology.
Overall, this workshop creates a unique space to explore the rapidly evolving field of object re-identification and its profound impact on advancing the capabilities of multimedia analysis and retrieval.

**Key Words**  Multimedia Retrieval, Object Re-identification, Representation Learning, Deep Metric Learning, Multi-view Generation 

**The list of possible topics includes, but is not limited to:**
* New Datasets and Benchmarks
* Deep Metric Learning
* Multi-view Data Generation
* Video-based Object Re-identification
* Cross-domain Object Re-identification
* Object Re-identification Domain Adaptation / Generalization
* Single/ Multiple Object Tracking
* Object Geo-localization
* Multimedia Re-ranking 

## Submission 

Submission Site is at [OpenReview](https://openreview.net/group?id=ACM.org/TheWebConf/2025/Workshop/MORE)  

Submission template can be found at [ACM](https://www.acm.org/publications/proceedings-template) or you may directly follow the [overleaf template](https://www.overleaf.com/read/yfpxtyngmzjn).

## Submission Type
**(1).** Original papers (up to 4 pages in length, plus unlimited pages for references): original solution to the tasks in the scope of workshop topics and themes.

**(2).** Challenge papers (up to 4 pages in length, plus unlimited pages for references): winning papers for our challenge; 

**(3).** Survey papers (up to 4 pages in length, plus unlimited pages for references): papers summarizing existing publications in leading conferences and high-impact journals that are relevant for the topic of the workshop;
Page limits include diagrams and appendices. 

Submissions should be single-blind due to limited publication time, written in English, and formatted according to the current ACM two-column conference format. 
Suitable LaTeX, Word, and Overleaf templates are available from the ACM Website (use “sigconf” proceedings template for LaTeX and the Interim Template for Word). 

## Important Dates

**Submission of papers:**
* Workshop Paper Submission Start: 27 Nov, 2024
* Challenge Start: 1 Dec, 2024
* Challenge End: 14 Dec, 2024
* Workshop Paper Submission End: 18 Dec, 2024
* Workshop Papers Notification: 23 Dec, 2024
* Camera-ready Submission: 25 Dec, 2024
* Workshop Dates: 28-29 Apr, 2025

Please note: The submission deadline is at 11:59 p.m. of the stated deadline date [Anywhere on Earth](https://time.is/Anywhere_on_Earth)

### Tips:

* For privacy protection, please blur faces in the published materials (such as paper, video, poster, etc.)
* For social good, please do not contain any misleading words, such as `surveillance` and `secret`.


## Organizing Team

|<img src="https://zdzheng.xyz/files/yaxiong-wang.jpeg" width="160">| <img src="https://hou-yz.github.io/images/id_jervis_bay.jpeg" width="160"> | <img src="https://github.com/layumi/MORE2025/blob/main/shuyu.jpg?raw=true" width="160">  | 
| :-: | :-: | :-: |
|  [Yaxiong Wang](https://dblp.org/pid/202/3251.html), Hefei University of Technology, China | [Yunzhong Hou](https://hou-yz.github.io/), Australian National University, Australia| Shuyu Yang, Xi'an Jiaotong University, China|
| <img src="https://github.com/layumi/ICME2022SS/blob/main/picture/1.png?raw=true" width="160">  | <img src="https://zdzheng.xyz/files/zhun-zhong.jpg" width="160"> | <img src="https://zheng-lab-anu.github.io/1.jpg" width="160"> | 
|  [Zhedong Zheng](https://zdzheng.xyz), University of Macau, China | [Zhun Zhong](https://zhunzhong.site), University of Nottingham, United Kingdom |  [Liang Zheng](https://zheng-lab-anu.github.io), Australian National University, Australia | 


## Workshop Citation
```
@inproceedings{wang2025MORE,
  title={MORE'25 Multimedia Object Re-ID: Advancements, Challenges, and Opportunities},
  author={Wang, Yaxiong and Hou, Yunzhong and Yang, Shuyu and Zheng, Zhedong and Zhong, Zhun and Zheng, Liang},
  booktitle={ACM Web Conference Workshop},
  year={2025}
}
```

